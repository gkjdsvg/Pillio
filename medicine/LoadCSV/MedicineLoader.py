import csv
import os.path
import re
from collections import defaultdict
from email.policy import default

import chardet   # pip install chardet
import unicodedata
from pathlib import Path

from LoadCSV.Medicine import Medicine


class Medicine:
    def __init__(self, name, ingredient_code, product_code, company, date, notice_number, detail, note, insurance, source_file=None):
        self.product_code = product_code # ì œí’ˆ ì½”ë“œ
        self.ingredient_code = ingredient_code # ì„±ë¶„ ì½”ë“œ
        self.item_name = name # ì•½ ì´ë¦„
        self.company = company # ì œì•½ì‚¬
        self.date = date # ê³µê³ ì¼ì
        self.notice_number = notice_number # ê³µê³  ë²ˆí˜¸
        self.detail = detail # ì•½í’ˆìƒì„¸ì •ë³´
        self.note = note # ë¹„ê³ 
        self.insurance = insurance # ê¸‰ì—¬ ì—¬ë¶€
        self.source_file = source_file # íŒŒì¼ ì´ë¦„

    def __repr__(self):
        return f"Medicine(name={self.item_name}, company={self.company})"


class MedicineLoader:
    def __init__(self):
        self.medicine_map = []
        self.files = [
            "csv/ì˜ì•½í’ˆì•ˆì „ì‚¬ìš©ì„œë¹„ìŠ¤(DUR)_ë…¸ì¸ì£¼ì˜ í’ˆëª©ë¦¬ìŠ¤íŠ¸ 2025.6.csv",
            "csv/ì˜ì•½í’ˆì•ˆì „ì‚¬ìš©ì„œë¹„ìŠ¤(DUR)_ë…¸ì¸ì£¼ì˜(í•´ì—´ì§„í†µì†Œì—¼ì œ) í’ˆëª©ë¦¬ìŠ¤íŠ¸ 2025.6.csv",
            "csv/ì˜ì•½í’ˆì•ˆì „ì‚¬ìš©ì„œë¹„ìŠ¤(DUR)_ë³‘ìš©ê¸ˆê¸° í’ˆëª©ë¦¬ìŠ¤íŠ¸ 2025.6.csv",
            "csv/ì˜ì•½í’ˆì•ˆì „ì‚¬ìš©ì„œë¹„ìŠ¤(DUR)_ì—°ë ¹ê¸ˆê¸° í’ˆëª©ë¦¬ìŠ¤íŠ¸ 2025.6.csv",
            "csv/ì˜ì•½í’ˆì•ˆì „ì‚¬ìš©ì„œë¹„ìŠ¤(DUR)_ì„ë¶€ê¸ˆê¸° í’ˆëª©ë¦¬ìŠ¤íŠ¸ 2025.6.csv",
        ]

    def detect_encoding(self, path: Path) -> str:
        with open(path, "rb") as f:
            raw = f.read(4096)
        result = chardet.detect(raw)
        return result["encoding"] or "utf-8"

    def ensure_length(self, row, length=10):
        """í–‰ ê¸¸ì´ê°€ ì§§ìœ¼ë©´ '' ì±„ìš°ê¸°"""
        return row + [""] * (length - len(row))

    def normalize(self, text: str) -> str:
        if not text:
            return ""
        n = unicodedata.normalize("NFKC", text)
        n = n.strip()
        n = n.replace("\ufeff", "").replace("\u00a0", "")  # BOM, NBSP ì œê±°
        # í—ˆìš© ë¬¸ìë§Œ ë‚¨ê¸°ê¸° (í•œê¸€, ì˜ë¬¸, ìˆ«ì)
        import re
        n = re.sub(r"[^ê°€-í£a-zA-Z0-9]", "", n)
        return n.lower()

    def load_csv(self):
        for f in self.files:
            path = Path(f)

            # ì¸ì½”ë”© ê°ì§€
            encoding = self.detect_encoding(path)
            print(f"ğŸ” {f} - detected encoding = {encoding}")

            if "ì„ë¶€ê¸ˆê¸°" in f:
                encoding = "cp949"  # MS949ì™€ ë™ì¼

            # êµ¬ë¶„ìëŠ” íƒ­ or ì½¤ë§ˆ ìœ„ì£¼
            with open(path, "r", encoding=encoding, errors="ignore") as csvfile:
                sample = csvfile.readline()
                delimiter = "\t" if sample.count("\t") >= sample.count(",") else ","

            # ì‹¤ì œ CSV ì½ê¸°
            with open(path, "r", encoding=encoding, errors="ignore") as csvfile:
                self.medicine_map = [] # ì´ˆê¸°í™”
                reader = csv.reader(csvfile, delimiter=delimiter)
                next(reader, None)  # í—¤ë” ìŠ¤í‚µ
                line_no = 0
                for row in reader:
                    line_no += 1
                    cols = self.ensure_length(row, 10)
                    if cols[0].startswith("\ufeff"):
                        cols[0] = cols[0][1:]

                    m = Medicine(
                        cols[3],  # ì„±ë¶„ëª…
                        cols[0],  # ì œí’ˆ ì½”ë“œ
                        cols[1],  # ì„±ë¶„ ì½”ë“œ
                        cols[2],  # ì œí’ˆëª…
                        cols[4],  # ì—…ì†Œëª…
                        cols[5],  # ê³µê³ ì¼ì
                        cols[6],  # ê³µê³ ë²ˆí˜¸
                        cols[7],  # ì•½í’ˆìƒì„¸ì •ë³´
                        cols[8],  # ë¹„ê³ 
                        source_file=os.path.basename(f)
                    )
                    self.medicine_map.append(m)

                    if line_no <= 5:
                        print("â–¶ parsed row:", cols)

            print(f"âœ… {f} ë¡œë“œ ì™„ë£Œ, ì´ {len(self.medicine_map)} ê°œ")

    def find_by_name(self, name: str):
        q = self.normalize(name)
        return [m for m in self.medicine_map if self.normalize(m.item_name) == q]



    def search_by_partial_name(self, name: str):
        normalized_name = self.normalize(name)
        q = name.strip().lower()
        print(f"normalized_name = {normalized_name}")

        matches = [m for m in self.medicine_map if q in m.item_name.lower()]

        grouped = defaultdict(lambda: {"detail": set(), "source_file": set()})
        for m in matches:
            base_name = re.sub(r"\d+ë°€ë¦¬ê·¸ë¨.$", "", m.item_name).strip()
            grouped[base_name]["detail"].add(m.insurance)
            grouped[base_name]["source_file"].add(m.source_file)

        result = []
        for item_name, info in grouped.items():
            result.append({
                "item_name": item_name,
                "detail": " / " .join(info["detail"]),
                "source_file": list(info["source_file"]),
            })

        print(result)

        return result

        # for m in self.medicine_map:
        #     normalized_item = self.normalize(m.item_name)
        #     if normalized_name in normalized_item:
        #         print(f"âœ… ë§¤ì¹­ë¨ :  {m.item_name}")
        #         yield m



    def debug_find(self, query: str):
        q_trim = query.strip()
        q_lower = q_trim.lower()
        q_norm = self.normalize(q_trim)

        print(f"â–¶ debugFind - raw query: [{query}]")
        print(f"   trimmed: [{q_trim}]")
        print(f"   lower: [{q_lower}]")
        print(f"   normalized: [{q_norm}]")

        for i, m in enumerate(self.medicine_map[:20]):
            print(i, "item_name_repr:", repr(getattr(m, "item_name", None)))
            print(" attrs:", m.__dict__)
            print("-" * 40)

        any_exact = any_ignore = any_norm = False
        for idx, m in enumerate(self.medicine_map):
            item = m.item_name or ""
            it_trim = item.strip()
            it_lower = it_trim.lower()
            it_norm = self.normalize(it_trim)

            if it_trim == q_trim:
                print(f"== exact match at index {idx}: [{item}]")
                any_exact = True
                break
            if not any_ignore and it_lower == q_lower:
                print(f"== equalsIgnoreCase match at index {idx}: [{item}]")
                any_ignore = True
            if not any_norm and it_norm == q_norm:
                print(f"== normalized-equals match at index {idx}: [{item}]")
                any_norm = True

        print(f"summary: exact={any_exact}, ignoreCase={any_ignore}, normalized={any_norm}")
